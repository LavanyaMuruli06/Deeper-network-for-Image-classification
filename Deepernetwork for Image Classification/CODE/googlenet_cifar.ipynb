{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0ihpkyFlgac",
        "outputId": "ebf83c8d-a676-40f0-dc90-0fbf38500852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.2.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->torchvision) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j2wptR55uH8",
        "outputId": "a80c4871-f697-4c97-c97c-3355c280e4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transforms for data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Download CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define class labels\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7l5TIX5846",
        "outputId": "dfd6c288-5e2b-42da-dc8e-add42ec61076"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 64)           9472      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 8, 8, 64)             0         ['conv2d_21[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 64)             4160      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 8, 8, 192)            110784    ['conv2d_22[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 4, 4, 192)            0         ['conv2d_23[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 4, 4, 96)             18528     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 4, 4, 16)             3088      ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 4, 4, 192)            0         ['max_pooling2d_7[0][0]']     \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 4, 4, 64)             12352     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 4, 4, 128)            110720    ['conv2d_25[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 4, 4, 32)             12832     ['conv2d_27[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 4, 4, 32)             6176      ['max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 4, 4, 256)            0         ['conv2d_24[0][0]',           \n",
            " )                                                                   'conv2d_26[0][0]',           \n",
            "                                                                     'conv2d_28[0][0]',           \n",
            "                                                                     'conv2d_29[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 4, 4, 128)            32896     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 4, 4, 32)             8224      ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 4, 4, 256)            0         ['concatenate_3[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 4, 4, 128)            32896     ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 4, 4, 192)            221376    ['conv2d_31[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 4, 4, 96)             76896     ['conv2d_33[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 4, 4, 64)             16448     ['max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 4, 4, 480)            0         ['conv2d_30[0][0]',           \n",
            " )                                                                   'conv2d_32[0][0]',           \n",
            "                                                                     'conv2d_34[0][0]',           \n",
            "                                                                     'conv2d_35[0][0]']           \n",
            "                                                                                                  \n",
            " max_pooling2d_10 (MaxPooli  (None, 2, 2, 480)            0         ['concatenate_4[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 2, 2, 96)             46176     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 2, 2, 16)             7696      ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d_11 (MaxPooli  (None, 2, 2, 480)            0         ['max_pooling2d_10[0][0]']    \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 2, 2, 192)            92352     ['max_pooling2d_10[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 2, 2, 208)            179920    ['conv2d_37[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 2, 2, 48)             19248     ['conv2d_39[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 2, 2, 64)             30784     ['max_pooling2d_11[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate_5 (Concatenate  (None, 2, 2, 512)            0         ['conv2d_36[0][0]',           \n",
            " )                                                                   'conv2d_38[0][0]',           \n",
            "                                                                     'conv2d_40[0][0]',           \n",
            "                                                                     'conv2d_41[0][0]']           \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 1, 1, 512)            0         ['concatenate_5[0][0]']       \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 1, 1, 512)            0         ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 512)                  0         ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   5130      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1058154 (4.04 MB)\n",
            "Trainable params: 1058154 (4.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 2.1178 - accuracy: 0.0927\n",
            "Epoch 1: val_accuracy improved from -inf to 0.09560, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 39s 81ms/step - loss: 2.1178 - accuracy: 0.0927 - val_loss: 1.8102 - val_accuracy: 0.0956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.7219 - accuracy: 0.0946\n",
            "Epoch 2: val_accuracy did not improve from 0.09560\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.7219 - accuracy: 0.0946 - val_loss: 1.5023 - val_accuracy: 0.0675\n",
            "Epoch 3/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.5236 - accuracy: 0.0960\n",
            "Epoch 3: val_accuracy did not improve from 0.09560\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.5236 - accuracy: 0.0960 - val_loss: 1.4101 - val_accuracy: 0.0891\n",
            "Epoch 4/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.4091 - accuracy: 0.0962\n",
            "Epoch 4: val_accuracy did not improve from 0.09560\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 1.4091 - accuracy: 0.0962 - val_loss: 1.2846 - val_accuracy: 0.0871\n",
            "Epoch 5/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.3132 - accuracy: 0.0957\n",
            "Epoch 5: val_accuracy improved from 0.09560 to 0.09980, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.3132 - accuracy: 0.0957 - val_loss: 1.1556 - val_accuracy: 0.0998\n",
            "Epoch 6/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.2427 - accuracy: 0.0980\n",
            "Epoch 6: val_accuracy improved from 0.09980 to 0.10200, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 1.2427 - accuracy: 0.0980 - val_loss: 1.0950 - val_accuracy: 0.1020\n",
            "Epoch 7/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.0974\n",
            "Epoch 7: val_accuracy improved from 0.10200 to 0.11810, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 1.1750 - accuracy: 0.0974 - val_loss: 1.1170 - val_accuracy: 0.1181\n",
            "Epoch 8/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.1156 - accuracy: 0.0985\n",
            "Epoch 8: val_accuracy did not improve from 0.11810\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 1.1156 - accuracy: 0.0985 - val_loss: 1.1018 - val_accuracy: 0.1129\n",
            "Epoch 9/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.0705 - accuracy: 0.1003\n",
            "Epoch 9: val_accuracy did not improve from 0.11810\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.0705 - accuracy: 0.1003 - val_loss: 0.9370 - val_accuracy: 0.1137\n",
            "Epoch 10/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 1.0143 - accuracy: 0.1008\n",
            "Epoch 10: val_accuracy did not improve from 0.11810\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 1.0143 - accuracy: 0.1008 - val_loss: 0.9180 - val_accuracy: 0.0920\n",
            "Epoch 11/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.9633 - accuracy: 0.0992\n",
            "Epoch 11: val_accuracy did not improve from 0.11810\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.9633 - accuracy: 0.0992 - val_loss: 0.8938 - val_accuracy: 0.0806\n",
            "Epoch 12/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.9331 - accuracy: 0.0994\n",
            "Epoch 12: val_accuracy improved from 0.11810 to 0.11920, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.9331 - accuracy: 0.0994 - val_loss: 0.8362 - val_accuracy: 0.1192\n",
            "Epoch 13/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.8961 - accuracy: 0.1003\n",
            "Epoch 13: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.8961 - accuracy: 0.1003 - val_loss: 0.7941 - val_accuracy: 0.1028\n",
            "Epoch 14/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.1018\n",
            "Epoch 14: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.8707 - accuracy: 0.1018 - val_loss: 0.8156 - val_accuracy: 0.0972\n",
            "Epoch 15/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.1022\n",
            "Epoch 15: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.8391 - accuracy: 0.1022 - val_loss: 0.7958 - val_accuracy: 0.0997\n",
            "Epoch 16/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.1020\n",
            "Epoch 16: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.8105 - accuracy: 0.1020 - val_loss: 0.8108 - val_accuracy: 0.1110\n",
            "Epoch 17/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7927 - accuracy: 0.1018\n",
            "Epoch 17: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7927 - accuracy: 0.1018 - val_loss: 0.7508 - val_accuracy: 0.1084\n",
            "Epoch 18/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7779 - accuracy: 0.1015\n",
            "Epoch 18: val_accuracy did not improve from 0.11920\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 0.7779 - accuracy: 0.1015 - val_loss: 0.7526 - val_accuracy: 0.0992\n",
            "Epoch 19/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7479 - accuracy: 0.1011\n",
            "Epoch 19: val_accuracy improved from 0.11920 to 0.12640, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7479 - accuracy: 0.1011 - val_loss: 0.7747 - val_accuracy: 0.1264\n",
            "Epoch 20/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.1013\n",
            "Epoch 20: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.7348 - accuracy: 0.1013 - val_loss: 0.7207 - val_accuracy: 0.1105\n",
            "Epoch 21/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7250 - accuracy: 0.1018\n",
            "Epoch 21: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.7250 - accuracy: 0.1018 - val_loss: 0.7394 - val_accuracy: 0.1057\n",
            "Epoch 22/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.1009\n",
            "Epoch 22: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.7115 - accuracy: 0.1009 - val_loss: 0.7534 - val_accuracy: 0.1104\n",
            "Epoch 23/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6970 - accuracy: 0.1010\n",
            "Epoch 23: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.6970 - accuracy: 0.1010 - val_loss: 0.7277 - val_accuracy: 0.1124\n",
            "Epoch 24/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6749 - accuracy: 0.1002\n",
            "Epoch 24: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.6749 - accuracy: 0.1002 - val_loss: 0.6945 - val_accuracy: 0.1212\n",
            "Epoch 25/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.1012\n",
            "Epoch 25: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.6694 - accuracy: 0.1012 - val_loss: 0.7113 - val_accuracy: 0.0972\n",
            "Epoch 26/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.1013\n",
            "Epoch 26: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.6596 - accuracy: 0.1013 - val_loss: 0.7001 - val_accuracy: 0.1067\n",
            "Epoch 27/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6397 - accuracy: 0.1020\n",
            "Epoch 27: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6397 - accuracy: 0.1020 - val_loss: 0.6531 - val_accuracy: 0.1108\n",
            "Epoch 28/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6249 - accuracy: 0.1019\n",
            "Epoch 28: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.6249 - accuracy: 0.1019 - val_loss: 0.7232 - val_accuracy: 0.0987\n",
            "Epoch 29/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6224 - accuracy: 0.1009\n",
            "Epoch 29: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.6224 - accuracy: 0.1009 - val_loss: 0.6841 - val_accuracy: 0.1148\n",
            "Epoch 30/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6006 - accuracy: 0.1010\n",
            "Epoch 30: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.6006 - accuracy: 0.1010 - val_loss: 0.6232 - val_accuracy: 0.1103\n",
            "Epoch 31/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.6033 - accuracy: 0.1010\n",
            "Epoch 31: val_accuracy did not improve from 0.12640\n",
            "390/390 [==============================] - 28s 72ms/step - loss: 0.6033 - accuracy: 0.1010 - val_loss: 0.6247 - val_accuracy: 0.0997\n",
            "Epoch 32/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5896 - accuracy: 0.1004\n",
            "Epoch 32: val_accuracy improved from 0.12640 to 0.13450, saving model to googlenet_cifar10.h5\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5896 - accuracy: 0.1004 - val_loss: 0.6279 - val_accuracy: 0.1345\n",
            "Epoch 33/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.1001\n",
            "Epoch 33: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.5756 - accuracy: 0.1001 - val_loss: 0.6236 - val_accuracy: 0.1030\n",
            "Epoch 34/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5676 - accuracy: 0.1005\n",
            "Epoch 34: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5676 - accuracy: 0.1005 - val_loss: 0.6263 - val_accuracy: 0.1107\n",
            "Epoch 35/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.1017\n",
            "Epoch 35: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 28s 73ms/step - loss: 0.5579 - accuracy: 0.1017 - val_loss: 0.6102 - val_accuracy: 0.0916\n",
            "Epoch 36/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.1011\n",
            "Epoch 36: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 30s 76ms/step - loss: 0.5519 - accuracy: 0.1011 - val_loss: 0.6498 - val_accuracy: 0.1000\n",
            "Epoch 37/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.1014\n",
            "Epoch 37: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5444 - accuracy: 0.1014 - val_loss: 0.6014 - val_accuracy: 0.1120\n",
            "Epoch 38/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.1016\n",
            "Epoch 38: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.5334 - accuracy: 0.1016 - val_loss: 0.6195 - val_accuracy: 0.1208\n",
            "Epoch 39/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.1005\n",
            "Epoch 39: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 31s 78ms/step - loss: 0.5233 - accuracy: 0.1005 - val_loss: 0.6374 - val_accuracy: 0.0995\n",
            "Epoch 40/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.1007\n",
            "Epoch 40: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5133 - accuracy: 0.1007 - val_loss: 0.6915 - val_accuracy: 0.1037\n",
            "Epoch 41/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.1011\n",
            "Epoch 41: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 31s 79ms/step - loss: 0.5228 - accuracy: 0.1011 - val_loss: 0.6542 - val_accuracy: 0.0980\n",
            "Epoch 42/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5056 - accuracy: 0.1007\n",
            "Epoch 42: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.5056 - accuracy: 0.1007 - val_loss: 0.6599 - val_accuracy: 0.1077\n",
            "Epoch 43/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.1009\n",
            "Epoch 43: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.5007 - accuracy: 0.1009 - val_loss: 0.5926 - val_accuracy: 0.1026\n",
            "Epoch 44/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4927 - accuracy: 0.1011\n",
            "Epoch 44: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4927 - accuracy: 0.1011 - val_loss: 0.5869 - val_accuracy: 0.1031\n",
            "Epoch 45/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.1004\n",
            "Epoch 45: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 73ms/step - loss: 0.4866 - accuracy: 0.1004 - val_loss: 0.5883 - val_accuracy: 0.1138\n",
            "Epoch 46/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4884 - accuracy: 0.1003\n",
            "Epoch 46: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 30s 77ms/step - loss: 0.4884 - accuracy: 0.1003 - val_loss: 0.6484 - val_accuracy: 0.1053\n",
            "Epoch 47/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.1004\n",
            "Epoch 47: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4791 - accuracy: 0.1004 - val_loss: 0.5614 - val_accuracy: 0.1108\n",
            "Epoch 48/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.1011\n",
            "Epoch 48: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 30s 78ms/step - loss: 0.4629 - accuracy: 0.1011 - val_loss: 0.6118 - val_accuracy: 0.0963\n",
            "Epoch 49/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.1005\n",
            "Epoch 49: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 75ms/step - loss: 0.4671 - accuracy: 0.1005 - val_loss: 0.6433 - val_accuracy: 0.0900\n",
            "Epoch 50/50\n",
            "391/390 [==============================] - ETA: 0s - loss: 0.4600 - accuracy: 0.1009\n",
            "Epoch 50: val_accuracy did not improve from 0.13450\n",
            "390/390 [==============================] - 29s 74ms/step - loss: 0.4600 - accuracy: 0.1009 - val_loss: 0.5579 - val_accuracy: 0.0973\n",
            "Epoch 1: Accuracy = 0.09266000241041183\n",
            "Epoch 2: Accuracy = 0.09458000212907791\n",
            "Epoch 3: Accuracy = 0.09595999866724014\n",
            "Epoch 4: Accuracy = 0.096220001578331\n",
            "Epoch 5: Accuracy = 0.095660001039505\n",
            "Epoch 6: Accuracy = 0.09796000272035599\n",
            "Epoch 7: Accuracy = 0.09741999953985214\n",
            "Epoch 8: Accuracy = 0.09845999628305435\n",
            "Epoch 9: Accuracy = 0.10034000128507614\n",
            "Epoch 10: Accuracy = 0.10075999796390533\n",
            "Epoch 11: Accuracy = 0.09920000284910202\n",
            "Epoch 12: Accuracy = 0.09942000359296799\n",
            "Epoch 13: Accuracy = 0.10029999911785126\n",
            "Epoch 14: Accuracy = 0.1017799973487854\n",
            "Epoch 15: Accuracy = 0.10220000147819519\n",
            "Epoch 16: Accuracy = 0.10196000337600708\n",
            "Epoch 17: Accuracy = 0.10181999951601028\n",
            "Epoch 18: Accuracy = 0.10153999924659729\n",
            "Epoch 19: Accuracy = 0.10108000040054321\n",
            "Epoch 20: Accuracy = 0.1012599989771843\n",
            "Epoch 21: Accuracy = 0.10181999951601028\n",
            "Epoch 22: Accuracy = 0.10087999701499939\n",
            "Epoch 23: Accuracy = 0.1009799987077713\n",
            "Epoch 24: Accuracy = 0.10019999742507935\n",
            "Epoch 25: Accuracy = 0.10118000209331512\n",
            "Epoch 26: Accuracy = 0.10134000331163406\n",
            "Epoch 27: Accuracy = 0.10199999809265137\n",
            "Epoch 28: Accuracy = 0.10189999639987946\n",
            "Epoch 29: Accuracy = 0.10090000182390213\n",
            "Epoch 30: Accuracy = 0.10103999823331833\n",
            "Epoch 31: Accuracy = 0.10096000134944916\n",
            "Epoch 32: Accuracy = 0.10038000345230103\n",
            "Epoch 33: Accuracy = 0.10010000318288803\n",
            "Epoch 34: Accuracy = 0.10053999722003937\n",
            "Epoch 35: Accuracy = 0.10171999782323837\n",
            "Epoch 36: Accuracy = 0.10108000040054321\n",
            "Epoch 37: Accuracy = 0.10143999755382538\n",
            "Epoch 38: Accuracy = 0.10155999660491943\n",
            "Epoch 39: Accuracy = 0.10047999769449234\n",
            "Epoch 40: Accuracy = 0.1006999984383583\n",
            "Epoch 41: Accuracy = 0.10113999992609024\n",
            "Epoch 42: Accuracy = 0.1006999984383583\n",
            "Epoch 43: Accuracy = 0.10091999918222427\n",
            "Epoch 44: Accuracy = 0.1011200025677681\n",
            "Epoch 45: Accuracy = 0.10040000081062317\n",
            "Epoch 46: Accuracy = 0.1003199964761734\n",
            "Epoch 47: Accuracy = 0.10041999816894531\n",
            "Epoch 48: Accuracy = 0.1011200025677681\n",
            "Epoch 49: Accuracy = 0.10047999769449234\n",
            "Epoch 50: Accuracy = 0.10090000182390213\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Concatenate, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# Preprocessing\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# GoogLeNet model\n",
        "def inception_module(x, filters):\n",
        "    branch1x1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n",
        "\n",
        "    branch3x3 = Conv2D(filters[1], (1, 1), padding='same', activation='relu')(x)\n",
        "    branch3x3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(branch3x3)\n",
        "\n",
        "    branch5x5 = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(x)\n",
        "    branch5x5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(branch5x5)\n",
        "\n",
        "    branch_pool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_pool = Conv2D(filters[5], (1, 1), padding='same', activation='relu')(branch_pool)\n",
        "\n",
        "    output = Concatenate(axis=-1)([branch1x1, branch3x3, branch5x5, branch_pool])\n",
        "    return output\n",
        "\n",
        "input_layer = Input(shape=(32, 32, 3))\n",
        "x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)\n",
        "x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "x = inception_module(x, [64, 96, 128, 16, 32, 32])\n",
        "x = inception_module(x, [128, 128, 192, 32, 96, 64])\n",
        "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "x = inception_module(x, [192, 96, 208, 16, 48, 64])\n",
        "\n",
        "# Add more inception modules as needed...\n",
        "\n",
        "# Redefine model after the last inception module\n",
        "x = AveragePooling2D((2, 2), strides=(1, 1), padding='valid')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Flatten()(x)\n",
        "output_layer = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Define model checkpoint callback\n",
        "checkpoint = ModelCheckpoint(\"googlenet_cifar10.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Train the model\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "history = model.fit(datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
        "                    steps_per_epoch=len(train_images) / batch_size, epochs=epochs,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    callbacks=[checkpoint])\n",
        "\n",
        "# Print epoch and accuracy after each training epoch\n",
        "for epoch, acc in enumerate(history.history['accuracy']):\n",
        "    print(f\"Epoch {epoch+1}: Accuracy = {acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "Rd_szhvhRx2c",
        "outputId": "ea3dd553-c4a5-44fb-9c45-7e375040a1ee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x1000 with 5 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Printing some trained images\n",
        "def plot_images(images, labels, class_names, num_images=5):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[labels[i][0]])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plotting some images\n",
        "plot_images(test_images, test_labels, class_names=[\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"])\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}